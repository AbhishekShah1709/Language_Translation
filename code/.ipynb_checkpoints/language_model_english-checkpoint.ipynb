{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "kmRj9TetPnaM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaCu8eUSoTIa",
    "outputId": "bcd13b80-8392-47a9-ae0f-891bd62e29ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "VeF5dtaRPnaR"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \n",
    "    f = open(path,'r')\n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "KeF8NExRmvto"
   },
   "outputs": [],
   "source": [
    "def make_n_grams(data, n):\n",
    "\n",
    "  all_X = []\n",
    "  all_y = []\n",
    "\n",
    "  for line in data:\n",
    "    if len(line)<=n:\n",
    "      continue\n",
    "\n",
    "    else:\n",
    "      for i in range(0, len(line)-n):\n",
    "        X = line[i:i+n]\n",
    "        y = line[i+n]\n",
    "\n",
    "        all_X.append(np.asarray(X))\n",
    "        all_y.append(y)\n",
    "\n",
    "  all_X = np.asarray(all_X)\n",
    "  all_y = np.asarray(all_y)\n",
    "\n",
    "  return all_X, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "dr_jNcHyYPZt"
   },
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    vocab = tokenizer.word_index\n",
    "    vocab_size = len(vocab) + 1\n",
    "    encoded_data = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    return encoded_data, vocab, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "qz-BVHABSWgT"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "\n",
    "  data, vocab, eng_tokenizer = tokenize_data(data)\n",
    "  X, y = make_n_grams(data, 8)\n",
    "\n",
    "  return X, y, vocab, eng_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "cHl8AH60Sv8X"
   },
   "outputs": [],
   "source": [
    "eng_train = load_data('/content/drive/MyDrive/europarl-corpus/train.europarl')\n",
    "X, y, eng_vocab, eng_tokenizer = preprocess_data(eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "VXtOKSw2WRAM"
   },
   "outputs": [],
   "source": [
    "reverse_vocab = {}\n",
    "\n",
    "for k,v in eng_vocab.items():\n",
    "  reverse_vocab[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "K-tA_py_PnaX"
   },
   "outputs": [],
   "source": [
    "num_tokens = len(eng_vocab)+1\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "MEmLC-6BPnaY"
   },
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(num_tokens, embedding_dim, trainable=True)\n",
    "\n",
    "def language_model():\n",
    "    \n",
    "    inp = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    embedded_sequences = embedding_layer(inp)\n",
    "\n",
    "    lstm = tf.keras.layers.LSTM(256)\n",
    "    rep = lstm(embedded_sequences)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(num_tokens, activation=\"softmax\")\n",
    "    output = dense(rep)\n",
    "\n",
    "    model = tf.keras.Model(inp, output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "4rPFAJvuPnaZ"
   },
   "outputs": [],
   "source": [
    "model = language_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyw6Y6PJPnaZ",
    "outputId": "6eaa7685-1fe2-468d-a6dc-a991403b92c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 100)         1512500   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               365568    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 15125)             3887125   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,765,193\n",
      "Trainable params: 5,765,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBXRLM3rPnaa",
    "outputId": "171aaa25-cfbd-47c6-d1d7-ab8b5649a06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2783/2783 [==============================] - 586s 210ms/step - loss: 5.9017 - acc: 0.1557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb63a06ed0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THXMg914kni0",
    "outputId": "df4036b5-cac0-47ab-cbb8-794de014b7ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/question1_epoch10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/question1_epoch10/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7feb65f439d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"/content/drive/MyDrive/question1_epoch10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "D_KQVHvnR2YJ"
   },
   "outputs": [],
   "source": [
    "eng_test = load_data('/content/drive/MyDrive/europarl-corpus/test.europarl')\n",
    "eng_test_data = eng_tokenizer.texts_to_sequences(eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "jA76VYjmfaNd"
   },
   "outputs": [],
   "source": [
    "test_X, test_y = make_n_grams(eng_test_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "l86Jsu_4TLne"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_X, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "krG0X9g8TwH2"
   },
   "outputs": [],
   "source": [
    "def decode_pred(preds):\n",
    "    \n",
    "    all_preds_idx = []\n",
    "    all_preds = []\n",
    "\n",
    "    for i in range(preds.shape[0]):\n",
    "      val = np.argmax(preds[i])\n",
    "      all_preds_idx.append(val)\n",
    "      \n",
    "    for val in all_preds_idx:\n",
    "      all_preds.append(reverse_vocab[val])\n",
    "      \n",
    "    all_preds_idx = np.asarray(all_preds_idx)\n",
    "    all_preds = np.asarray(all_preds)\n",
    "    \n",
    "    return all_preds_idx, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "hE96WC7rUQRA"
   },
   "outputs": [],
   "source": [
    "dec_preds, dec_preds_word = decode_pred(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "NCYetwbdJOBC"
   },
   "outputs": [],
   "source": [
    "def get_perplexity(sent):\n",
    "\n",
    "  perp = 0\n",
    "  if len(sent)<4:\n",
    "    return 0\n",
    "  else:\n",
    "    cnt=0\n",
    "    for i in range(len(sent)-4):\n",
    "      cnt+=1\n",
    "      inp = sent[i:i+4]\n",
    "\n",
    "      inp = inp.reshape(1,-1)\n",
    "      pred = model.predict(inp)\n",
    "      val = np.max(pred)\n",
    "\n",
    "      perp += math.log(val)/math.log(2)\n",
    "    \n",
    "    return (-1*perp)/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_7WfzUXYSE_",
    "outputId": "e02f40b0-2103-4c63-b520-232aa91adbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumption of the session\t2.899883634135354\n",
      "I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\t2.025733719206991\n",
      "Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\t2.4543161840810472\n",
      "You have requested a debate on this subject in the course of the next few days, during this part-session.\t2.675161205373426\n",
      "In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\t2.3873106445711922\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(X[:5]):\n",
    "  perp = get_perplexity(np.asarray(sent))\n",
    "  print(eng_train[i].split(\"\\n\")[0], end=\"\\t\")\n",
    "  print(perp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcFXpAOmZAhM",
    "outputId": "fdbdbb68-41a6-43ba-9a24-e02332ae8a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When used preventively, it saves the state and the economy a great deal of money.\t3.6488758710538525\n",
      "I have completely failed to understand in this debate why a reasonable set of rules was not adopted back in 1993, especially as the Commission and Parliament did not want any derogations even then.\t3.3339458113589893\n",
      "Seven million workers were affected and specific sectors, such as the mobile worker sector, have been subject to ruinous competition over recent years, especially in Germany.\t3.118494075404921\n",
      "It is therefore also a social problem and it is not enough, Mr Crowley, to use tachographs or other technical aids.\t3.7744358820129635\n",
      "One does not exclude the other.\t3.612589429540818\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(eng_test_data[:5]):\n",
    "  perp = get_perplexity(np.asarray(sent))\n",
    "  print(eng_test[i].split(\"\\n\")[0], end=\"\\t\")\n",
    "  print(perp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "language_model_english.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
